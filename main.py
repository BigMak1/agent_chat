import time
from typing import List
import os
import json

from yandex_cloud_ml_sdk import YCloudML
from langchain_chroma import Chroma
from yandex_chain import YandexEmbeddings
import langchain.chains
import langchain.prompts
from yandex_chain import YandexLLM, YandexGPTModel
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

from fastapi import FastAPI, HTTPException, Request, Response
from pydantic import HttpUrl
from schemas.request import PredictionRequest, PredictionResponse
from utils.logger import setup_logger

# Initialize
app = FastAPI()
llm = YandexLLM(folder_id=os.getenv("CATALOG_ID"), api_key=os.getenv("API_KEY"), model=YandexGPTModel.Pro, temperature=0.05, retries=3)
embeddings = YandexEmbeddings(folder_id=os.getenv("CATALOG_ID"), api_key=os.getenv("API_KEY"), retries=3)
qdb = Chroma(embedding_function=embeddings, persist_directory='./source/chroma_hypoq_db')
retriever = qdb.as_retriever(search_type="similarity", search_kwargs={"k": 2})
logger = None

prompt = """
## Задача
Ты — языковая модель, которая формирует ответы на вопросы об Университете ИТМО 
с разными вариантами ответов. Каждый вариант ответа соответствует определённому 
утверждению или факту. Твоя задача - определить правильный вариант ответа и вернуть его 
в поле answer JSON-ответа.

1. Формат вопроса:
- Вопрос всегда начинается с текстового описания. 
- После описания перечисляются варианты ответов, каждый из которых пронумерован цифрой от 1 до 10. 
- Варианты ответов разделяются символом новой строки (\n).

2. Формат JSON-ответа:
- `answer` (число или `null`) — правильный ответ, если вопрос подразумевает выбор из вариантов. Если нет — `null`.
- `reasoning` (строка) — объяснение выбора ответа или дополнительная информация.
- `sources` (массив строк) — список ссылок на источники информации, откуда был получен ответ.

Текст ниже может помочь ответить на вопрос. Если ответа в тексте нет, по найди ответ самостоятельно стандартным способом и дай свою ссылку на источник.
Текст:
-----
{context}
-----
Вопрос:
{question}
"""


prompt = langchain.prompts.PromptTemplate(
    template=prompt, input_variables=["context", "question"]
)


# Retriver func
def xretriever(q):
    res = retriever.invoke(q)
    res_out = '\n'.join(set([x.page_content for x in res]))
    res_out += f"Источники представлены по следующим ссылкам: {['https://news.itmo.ru' + x.metadata['link'] for x in res]}. Можешь включить их в ответ"
    return res_out


chain = (
    {"context": xretriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)


@app.on_event("startup")
async def startup_event():
    global logger
    logger = await setup_logger()


@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()

    body = await request.body()
    await logger.info(
        f"Incoming request: {request.method} {request.url}\n"
        f"Request body: {body.decode('utf-8')}"
    )

    response = await call_next(request)
    process_time = time.time() - start_time

    response_body = b""
    async for chunk in response.body_iterator:
        response_body += chunk

    await logger.info(
        f"Request completed: {request.method} {request.url}\n"
        f"Status: {response.status_code}\n"
        f"Response body: {response_body.decode('utf-8')}\n"
        f"Duration: {process_time:.3f}s"
    )

    return Response(
        content=response_body,
        status_code=response.status_code,
        headers=dict(response.headers),
        media_type=response.media_type,
    )


@app.post("/api/request", response_model=PredictionResponse)
async def predict(body: PredictionRequest):
    try:
        await logger.info(f"Processing prediction request with id: {body.id}")


        # Здесь будет вызов вашей модели
        q = body.query
        response_json = json.loads(chain.invoke(q).strip("```").strip())

        answer = response_json["answer"]  # Замените на реальный вызов модели
        reasoning = response_json["reasoning"] + "Generated by YandexGPT Pro Model."
        sources = [HttpUrl(link) for link in response_json["sources"]]

        response = PredictionResponse(
            id=body.id,
            answer=answer,
            reasoning=reasoning,
            sources=sources,
        )
        await logger.info(f"Successfully processed request {body.id}")
        return response
    
    except ValueError as e:
        error_msg = str(e)
        await logger.error(f"Validation error for request {body.id}: {error_msg}")
        raise HTTPException(status_code=400, detail=error_msg)
    
    except Exception as e:
        await logger.error(f"Internal error processing request {body.id}: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal server error")
